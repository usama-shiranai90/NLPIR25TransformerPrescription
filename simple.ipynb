{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Jupyter notebook sample"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T10:36:47.546645Z",
     "start_time": "2025-09-11T10:36:47.535933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, csv, time, requests, sys\n",
    "from urllib.parse import urlencode\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Calculate the sums\n",
    "import os, csv, time, requests, xml.etree.ElementTree as ET"
   ],
   "id": "7df9140457caed5e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-11T10:42:54.345790Z",
     "start_time": "2025-09-11T10:36:48.850962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAILTO = \"bukhari.453@s.kyushu-u.ac.jp\"\n",
    "OUT_CSV = \"openalex_works.csv\"\n",
    "\n",
    "QUERY_HUMAN = r'''(transformer* OR \"self-attention\" OR BERT OR GPT OR \"large language model\" OR \"retrieval-augmented generation\") AND (prescrib* OR medicat* OR \"drug\" OR pharmac* OR \"medication recommendation\" OR prescription)'''.strip()\n",
    "DATE_FROM, DATE_TO = \"2020-01-01\", \"2025-05-31\"\n",
    "\n",
    "BASE = \"https://api.openalex.org/works\"\n",
    "\n",
    "# We search fulltext fields, then filter by date, language, and has_doi if you like\n",
    "params = {\n",
    "    \"search\": QUERY_HUMAN,\n",
    "    \"filter\": f\"from_publication_date:{DATE_FROM},to_publication_date:{DATE_TO}\",\n",
    "    \"per_page\": 200,\n",
    "    \"cursor\": \"*\",\n",
    "    \"mailto\": MAILTO,\n",
    "}\n",
    "\n",
    "fields = [\"id\", \"doi\", \"title\", \"publication_year\", \"publication_date\",\n",
    "          \"authorships\", \"host_venue\", \"type\", \"open_access\", \"cited_by_count\", \"abstract_inverted_index\",\n",
    "          \"primary_topic\"]\n",
    "\n",
    "with open(OUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"source\", \"work_id\", \"doi\", \"title\", \"year\", \"date\", \"venue\", \"type\", \"is_oa\", \"oa_status\", \"cited_by\",\n",
    "                \"abstract\", \"authors\"])\n",
    "    total = 0\n",
    "    while True:\n",
    "        r = requests.get(BASE, params=params, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        j = r.json()\n",
    "        results = j.get(\"results\", [])\n",
    "        if not results: break\n",
    "        for x in results:\n",
    "            doi = (x.get(\"doi\") or \"\").lower().replace(\"https://doi.org/\", \"\")\n",
    "            title = x.get(\"title\") or \"\"\n",
    "            year = x.get(\"publication_year\") or \"\"\n",
    "            date = x.get(\"publication_date\") or \"\"\n",
    "            venue = (x.get(\"host_venue\") or {}).get(\"display_name\") or \"\"\n",
    "            wtype = x.get(\"type\") or \"\"\n",
    "            oa = x.get(\"open_access\") or {}\n",
    "            is_oa = oa.get(\"is_oa\")\n",
    "            oa_status = oa.get(\"oa_status\") or \"\"\n",
    "            cited_by = x.get(\"cited_by_count\") or 0\n",
    "            # Recompose abstract text if present\n",
    "            inv = x.get(\"abstract_inverted_index\")\n",
    "            abstract = \"\"\n",
    "            if isinstance(inv, dict):\n",
    "                words = sorted([(pos, word) for word, poss in inv.items() for pos in poss])\n",
    "                abstract = \" \".join(w for _, w in words)\n",
    "            # Simple author string\n",
    "            authors = \"; \".join(\n",
    "                [(a.get(\"author\", {}) or {}).get(\"display_name\", \"\") for a in x.get(\"authorships\") or []])\n",
    "            w.writerow(\n",
    "                [\"OpenAlex\", x.get(\"id\"), doi, title, year, date, venue, wtype, is_oa, oa_status, cited_by, abstract,\n",
    "                 authors])\n",
    "            total += 1\n",
    "        params[\"cursor\"] = j.get(\"meta\", {}).get(\"next_cursor\")\n",
    "        if not params[\"cursor\"]: break\n",
    "        time.sleep(0.1)\n",
    "\n",
    "print(f\"Saved {total} OpenAlex records to {OUT_CSV}\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 19095 OpenAlex records to openalex_works.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "EMAIL = \"your.email@institution.edu\"  # NCBI asks for email/tool id\n",
    "TOOL = \"your_tool_name\"\n",
    "\n",
    "QUERY_HUMAN = r'''(transformer*[Title/Abstract] OR \"self-attention\"[Title/Abstract] OR BERT[Title/Abstract] OR GPT[Title/Abstract] OR \"large language model\"[Title/Abstract] OR \"retrieval-augmented generation\"[Title/Abstract]) AND (prescrib*[Title/Abstract] OR medicat*[Title/Abstract] OR drug[Title/Abstract] OR pharmac*[Title/Abstract] OR \"medication recommendation\"[Title/Abstract] OR prescription[Title/Abstract])'''.strip()\n",
    "DATE_FROM, DATE_TO = \"2020/01/01\", \"2025/05/31\"  # PubMed date format\n",
    "\n",
    "OUT_CSV = \"pubmed_works.csv\"\n",
    "\n",
    "\n",
    "def esearch(term, retmax=100000):\n",
    "    base = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    params = {\n",
    "        \"db\": \"pubmed\", \"term\": term,\n",
    "        \"datetype\": \"pdat\", \"mindate\": DATE_FROM, \"maxdate\": DATE_TO,\n",
    "        \"retmax\": retmax, \"retmode\": \"json\",\n",
    "        \"usehistory\": \"y\", \"tool\": TOOL, \"email\": EMAIL\n",
    "    }\n",
    "    r = requests.get(base, params=params, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def efetch(webenv, query_key, retstart, retmax=200):\n",
    "    base = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "    params = {\n",
    "        \"db\": \"pubmed\", \"query_key\": query_key, \"WebEnv\": webenv,\n",
    "        \"retstart\": retstart, \"retmax\": retmax,\n",
    "        \"retmode\": \"xml\", \"tool\": TOOL, \"email\": EMAIL\n",
    "    }\n",
    "    r = requests.get(base, params=params, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "\n",
    "def get_text(elem, path):\n",
    "    x = elem.find(path)\n",
    "    return x.text if x is not None and x.text else \"\"\n",
    "\n",
    "\n",
    "def parse_article(article):\n",
    "    med = article.find(\"MedlineCitation\")\n",
    "    pmid = get_text(med, \"PMID\")\n",
    "    art = med.find(\"Article\")\n",
    "    title = get_text(art, \"ArticleTitle\")\n",
    "    # Abstract (concat sections)\n",
    "    abstract = \" \".join([t.text for t in art.findall(\"Abstract/AbstractText\") if t is not None and t.text]) or \"\"\n",
    "    # Year\n",
    "    y = get_text(art, \"Journal/JournalIssue/PubDate/Year\")\n",
    "    if not y:\n",
    "        y = get_text(art, \"Journal/JournalIssue/PubDate/MedlineDate\")[:4]\n",
    "    # Journal\n",
    "    journal = get_text(art, \"Journal/Title\")\n",
    "    # DOI\n",
    "    doi = \"\"\n",
    "    for aid in art.findall(\"ELocationID\"):\n",
    "        if aid.get(\"EIdType\", \"\").lower() == \"doi\" and aid.text:\n",
    "            doi = aid.text.lower().strip()\n",
    "            break\n",
    "    if not doi:\n",
    "        for el in med.findall(\"ArticleIdList/ArticleId\"):\n",
    "            if el.get(\"IdType\", \"\").lower() == \"doi\" and el.text:\n",
    "                doi = el.text.lower().strip()\n",
    "                break\n",
    "    # MeSH\n",
    "    mesh_terms = [get_text(x, \"DescriptorName\") for x in med.findall(\"MeshHeadingList/MeshHeading\")]\n",
    "    authors = []\n",
    "    for a in art.findall(\"AuthorList/Author\"):\n",
    "        last = get_text(a, \"LastName\");\n",
    "        fore = get_text(a, \"ForeName\")\n",
    "        if last or fore: authors.append((\" \".join([fore, last])).strip())\n",
    "    return {\n",
    "        \"source\": \"PubMed\", \"pmid\": pmid, \"doi\": doi, \"title\": title, \"year\": y, \"date\": \"\", \"venue\": journal,\n",
    "        \"type\": \"\", \"is_oa\": \"\", \"oa_status\": \"\", \"cited_by\": \"\",\n",
    "        \"abstract\": abstract, \"authors\": \"; \".join(authors), \"mesh\": \"; \".join(mesh_terms)\n",
    "    }\n",
    "\n",
    "\n",
    "# Run\n",
    "j = esearch(QUERY_HUMAN)\n",
    "webenv = j[\"esearchresult\"][\"webenv\"]\n",
    "qk = j[\"esearchresult\"][\"querykey\"]\n",
    "count = int(j[\"esearchresult\"][\"count\"])\n",
    "print(\"PubMed hits:\", count)\n",
    "\n",
    "with open(OUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    import csv\n",
    "\n",
    "    w = csv.DictWriter(f, fieldnames=[\"source\", \"pmid\", \"doi\", \"title\", \"year\", \"date\", \"venue\", \"type\", \"is_oa\",\n",
    "                                      \"oa_status\", \"cited_by\", \"abstract\", \"authors\", \"mesh\"])\n",
    "    w.writeheader()\n",
    "    for start in tqdm(range(0, count, 200)):\n",
    "        xml = efetch(webenv, qk, start, 200)\n",
    "        root = ET.fromstring(xml)\n",
    "        for art in root.findall(\"PubmedArticle\"):\n",
    "            rec = parse_article(art)\n",
    "            w.writerow(rec)\n",
    "        time.sleep(0.34)  # be polite to NCBI\n",
    "print(f\"Saved {count} PubMed records to {OUT_CSV}\")\n"
   ],
   "id": "e65e58a1b7e04493",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
